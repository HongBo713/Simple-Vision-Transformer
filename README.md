# Vision Transformer (ViT) Implementation

## Overview

This project is an implementation of the Vision Transformer (ViT), which leverages the self-attention mechanism to capture intricate relationships between image patches. The original implementation was developed by Tin Nguyen and can be found [here](https://github.com/tintn/vision-transformer-from-scratch). This version includes additional visualization features and simplified parts for educational purposes.

## Features

- **Self-Attention Mechanism**: Dynamically focuses on different parts of the input image.
- **Multi-Head Attention**: Captures features at different levels.
- **Visualization**: Visualizes the attention scores to understand how the model processes the image patches.

## Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/Simple-Vision-Transformer.git
   cd Simple-Vision-Transformer

### Explanation

- **Overview Section**: The original implementation was developed by Tin Nguyen and can be found [here](https://github.com/tintn/vision-transformer-from-scratch).
- **Acknowledgements Section**: The original implementation was developed by Tin Nguyen and can be found [here](https://github.com/tintn/vision-transformer-from-scratch).

This ensures that you are giving proper credit to the creators of the original implementation and maintaining transparency in your work.
